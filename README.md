# ğŸ“Š NPM Metrics Scraper

## Arquitectura del Proyecto

```
npm-metrics-scraper/
â”œâ”€â”€ npm-metrics-package/          # Carpeta principal del proyecto Scrapy
â”‚   â”œâ”€â”€ npm_metrics_package/      # Paquete Python con el cÃ³digo
â”‚   â”‚   â”œâ”€â”€ spiders/              # ğŸ•·ï¸ Los "robots" que hacen el scraping
â”‚   â”‚   â”‚   â””â”€â”€ package_info_spider.py  # Spider principal
â”‚   â”‚   â”œâ”€â”€ items.py              # ğŸ“‹ Define quÃ© datos queremos capturar
â”‚   â”‚   â”œâ”€â”€ pipelines.py          # ğŸ”§ Procesa los datos descargados
â”‚   â”‚   â”œâ”€â”€ settings.py           # âš™ï¸ ConfiguraciÃ³n del scraper
â”‚   â”‚   â””â”€â”€ middlewares.py        # ğŸ”Œ Middleware (no usado actualmente)
â”‚   â”œâ”€â”€ scrapy.cfg                # ConfiguraciÃ³n de Scrapy
â”‚   â”œâ”€â”€ requirements.txt          # Dependencias del proyecto
â”‚   â””â”€â”€ npm_metrics_results.json  # ğŸ’¾ Resultados generados
â””â”€â”€ README.md                     # ğŸ“– Este archivo
```

## Flujo de Trabajo

### **PASO A: Descubrimiento** ğŸ”
El spider comienza con una lista de paquetes (por ejemplo: `react`, `axios`, `lodash`).

```python
package_list = ['react', 'axios', 'lodash']
```

### **PASO B: API de Descargas** ğŸ“Š
Para cada paquete, consulta la API de NPM para obtener las **descargas del Ãºltimo mes**.

```
ğŸ“¡ https://api.npmjs.org/downloads/point/last-month/react
```

### **PASO C: API de Registro (Metadata)** ğŸ“
Luego consulta la Registry API de NPM para obtener informaciÃ³n detallada:

```
ğŸ“¡ https://registry.npmjs.org/react
```

**Datos que obtiene:**
- âœ… VersiÃ³n actual (`version`)
- âœ… DescripciÃ³n/propÃ³sito (`purpose`)
- âœ… Dependencias (`dependencies`)
- âœ… TamaÃ±o descomprimido (`size_mb`)
- âœ… Licencia (`license`)
- âœ… NÃºmero de mantenedores (`maintainer_count`)
- âœ… Ãšltima modificaciÃ³n (`last_modified`)
- âœ… URL del tarball (para descarga)
- âœ… URL pÃºblica del paquete

### **PASO D: AnÃ¡lisis Local de CÃ³digo** ğŸ”¬
El Pipeline descarga el archivo `.tgz` del paquete y analiza:

1. **Descarga el tarball** (archivo comprimido del paquete)
2. **Descomprime** en una carpeta temporal
3. **Cuenta archivos** JavaScript/TypeScript (`.js`, `.ts`, `.jsx`, `.tsx`)
4. **Simula conteo de funciones** (AST implementado)
5. **Limpia** la carpeta temporal

## ğŸ“‹ Datos Capturados

Para cada paquete NPM, el scraper recopila:

| Campo | DescripciÃ³n | Ejemplo |
|-------|-------------|---------|
| `package_name` | Nombre del paquete | `"react"` |
| `public_url` | URL pÃºblica en npmjs.com | `"https://www.npmjs.com/package/react"` |
| `purpose` | DescripciÃ³n corta | `"React is a JavaScript library..."` |
| `downloads_last_month` | Descargas del Ãºltimo mes | 
| `version` | VersiÃ³n actual |
| `size_mb` | TamaÃ±o descomprimido en MB |
| `dependencies` | Dependencias del paquete | `{}` o `{"lodash": "^4.17.0"}` |
| `license` | Tipo de licencia |
| `maintainer_count` | NÃºmero de mantenedores |
| `last_modified` | Fecha de Ãºltima modificaciÃ³n |
| `total_files` | Archivos JS/TS en el paquete |
| `total_functions` | Funciones detectadas (simulado) |
| `tarball_url` | URL del archivo comprimido |

## ğŸš€ InstalaciÃ³n

### Requisitos Previos
- Python 3.11 o superior
- pip (gestor de paquetes de Python)

### Pasos de InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone https://github.com/AnaisRodriguez1/npm-metrics-scraper.git
cd npm-metrics-scraper
```

2. **Crear entorno virtual** (recomendado)
```bash
python -m venv .venv
```

3. **Activar el entorno virtual**

En Windows (PowerShell):
```powershell
.venv\Scripts\Activate.ps1
```

En Windows (CMD):
```cmd
.venv\Scripts\activate.bat
```

En Linux/Mac:
```bash
source .venv/bin/activate
```

4. **Instalar dependencias**
```bash
cd npm-metrics-package
pip install -r requirements.txt
```

## ğŸ’» Uso

### Ejecutar el Scraper

```bash
cd npm-metrics-package
scrapy crawl package_info_spider -o npm_metrics_results.json
```

### Cambiar los Paquetes a Analizar

Edita el archivo `npm_metrics_package/spiders/package_info_spider.py`:

```python
package_list = ['react', 'vue', 'angular', 'express', 'next']
```

### Ver los Resultados

Los resultados se guardan en `npm_metrics_results.json`:

## âš™ï¸ ConfiguraciÃ³n

### Ajustar la Velocidad del Scraping

En `npm_metrics_package/settings.py`:

```python
# Espera 1 segundo entre cada request (evita saturar el servidor)
DOWNLOAD_DELAY = 1

# Solo 1 request simultÃ¡neo por dominio
CONCURRENT_REQUESTS_PER_DOMAIN = 1
```

### Cambiar el User-Agent

```python
USER_AGENT = 'npm_metrics_package (tu-email@ejemplo.com)'
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **[Scrapy 2.13](https://scrapy.org/)** - Framework de web scraping
- **[Python 3.11](https://www.python.org/)** - Lenguaje de programaciÃ³n
- **[Requests](https://requests.readthedocs.io/)** - Para descargar tarballs
- **APIs de NPM:**
  - Downloads API: `api.npmjs.org`
  - Registry API: `registry.npmjs.org`